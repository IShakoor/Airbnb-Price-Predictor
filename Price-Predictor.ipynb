{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486bc67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data\n",
    "def load_data(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "# compute summary statistics of data\n",
    "def summarise_data(df):\n",
    "    print(df.describe())\n",
    "\n",
    "# call functions\n",
    "df = load_data('London_Listings.csv')\n",
    "summarise_data(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise missing values\n",
    "def visualize_missing_values(df, threshold=0.0):\n",
    "    # find percentage of missing vals\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "    # filter columns above threshold\n",
    "    missing_percent = missing_percent[missing_percent > threshold]\n",
    "\n",
    "    if missing_percent.empty:\n",
    "        print(\"No missing values above threshold found in the dataset.\")\n",
    "        return\n",
    "\n",
    "    # sort descending\n",
    "    missing_percent = missing_percent.sort_values(ascending=False)\n",
    "\n",
    "    # plot bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = missing_percent.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "    # annotate bars with %\n",
    "    for i, v in enumerate(missing_percent):\n",
    "        ax.text(i, v + 0.5, f\"{v:.1f}%\", ha='center', va='bottom', fontsize=8, rotation=90)\n",
    "\n",
    "    plt.title('Missing Values per Column (%)')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Percentage Missing')\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "visualize_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfe13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital basic data cleaning\n",
    "def initial_clean(df):\n",
    "    # replace N/A with np.nan\n",
    "    df.replace(\"N/A\", np.nan, inplace=True)\n",
    "    \n",
    "    # convert percentages\n",
    "    df['host_response_rate'] = df['host_response_rate'].str.rstrip('%').astype(float)\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].str.rstrip('%').astype(float)\n",
    "    \n",
    "    # remove dollar sign and comma from price\n",
    "    df['price'] = df['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "    # convert to bool\n",
    "    df['host_is_superhost'] = df['host_is_superhost'].map({'t': 1, 'f': 0})\n",
    "\n",
    "    # date parsing\n",
    "    date_cols = ['host_since', 'calendar_last_scraped', 'first_review', 'last_review']\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# dropping irrelvant cols & those with low predictive power\n",
    "def remove_cols(df):\n",
    "    cols_to_drop = [\n",
    "        'id',\n",
    "        'name',\n",
    "        'description',\n",
    "        'host_id',\n",
    "        'host_name',\n",
    "        'host_listings_count',\n",
    "        'calculated_host_listings_count',\n",
    "        'calendar_last_scraped'\n",
    "    ]\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "    return df\n",
    "\n",
    "df = remove_cols(initial_clean(df))\n",
    "summarise_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcc364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values - prevent skewing\n",
    "def handle_missing(df):\n",
    "    df = df.copy()\n",
    "    # remove rows with missing price\n",
    "    df = df[~df['price'].isnull()]\n",
    "\n",
    "    # replace review_scores_rating with NaN if there are no reviews\n",
    "    df['has_reviews'] = (df['number_of_reviews'] > 0).astype(int)\n",
    "    df.loc[df['number_of_reviews'] == 0, 'review_scores_rating'] = np.nan\n",
    "\n",
    "    # fill with grouped median of similar properties\n",
    "    df['review_scores_rating'] = df['review_scores_rating'].fillna(\n",
    "        df.groupby(['neighbourhood', 'room_type', 'accommodates'])['review_scores_rating'].transform('median')\n",
    "    )\n",
    "\n",
    "    # time since last reviews\n",
    "    today = pd.Timestamp('today')\n",
    "    df['days_since_first_review'] = (today - df['first_review']).dt.days.fillna(0)\n",
    "    df['days_since_last_review'] = (today - df['last_review']).dt.days.fillna(0)\n",
    "    df.drop(columns=['first_review', 'last_review'], inplace=True)\n",
    "\n",
    "    # flag missing response rates and fill with median\n",
    "    df['response_rate_missing'] = df['host_response_rate'].isnull().astype(int)\n",
    "    df['host_response_rate'] = df['host_response_rate'].fillna(df['host_response_rate'].median())\n",
    "\n",
    "    # flag missing acceptance rates and fill with median\n",
    "    df['acceptance_rate_missing'] = df['host_acceptance_rate'].isnull().astype(int)\n",
    "    df['host_acceptance_rate'] = df['host_acceptance_rate'].fillna(df['host_acceptance_rate'].median())\n",
    "\n",
    "    # fill with median for similar properties\n",
    "    df['beds'] = df.groupby(['accommodates', 'room_type'])['beds'].transform(\n",
    "        lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x.fillna(x.median())\n",
    "    )\n",
    "    df['bedrooms'] = df.groupby(['accommodates', 'room_type'])['bedrooms'].transform(\n",
    "        lambda x: x.fillna(x.mode().iloc[0]) if not x.mode().empty else x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    # fill with medians\n",
    "    df['bathrooms'] = df['bathrooms'].fillna(df['bathrooms'].median())\n",
    "    df['host_is_superhost'] = df['host_is_superhost'].fillna(df['host_is_superhost'].mode()[0])\n",
    "    df['host_total_listings_count'] =  df['host_total_listings_count'].fillna(df['host_total_listings_count'].median())\n",
    "    \n",
    "    # fill with median\n",
    "    median_date = df['host_since'].dropna().median()\n",
    "    df['host_since'] = df['host_since'].fillna(median_date)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = handle_missing(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform price\n",
    "def transform_price(df):\n",
    "    df['log_price'] = np.log1p(df['price'])\n",
    "\n",
    "# log transform listings count\n",
    "def transform_listings_count(df):\n",
    "    df['log_host_listings'] = np.log1p(df['host_total_listings_count'])\n",
    "\n",
    "# winsorise outliers\n",
    "def handle_outliers(df, columns, lower_q=0.01, upper_q=0.99):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            lower = df[col].quantile(lower_q)\n",
    "            upper = df[col].quantile(upper_q)\n",
    "            df[col] = df[col].clip(lower, upper)\n",
    "    return df\n",
    "\n",
    "transform_price(df)\n",
    "transform_listings_count(df)\n",
    "handle_outliers(df, ['beds','accommodates','bedrooms'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
